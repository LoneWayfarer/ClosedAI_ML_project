{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc_jdOBpysLJ",
        "outputId": "1c4bacf8-7098-4dbe-b8e2-e01ee3834d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lifestream in /usr/local/lib/python3.9/dist-packages (0.5.2)\n",
            "Requirement already satisfied: transformers==4.* in /usr/local/lib/python3.9/dist-packages (from pytorch-lifestream) (4.27.1)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lifestream) (9.0.0)\n",
            "Requirement already satisfied: pytorch-lightning==1.6.* in /usr/local/lib/python3.9/dist-packages (from pytorch-lifestream) (1.6.5)\n",
            "Requirement already satisfied: hydra-core>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lifestream) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (1.22.4)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (0.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (2.11.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (23.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (3.19.6)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (6.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (2023.3.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (0.11.4)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (3.9.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.9/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (2.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.8.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (63.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.16.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.51.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.40.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (1.26.15)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install pytorch-lifestream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0shS9Hoy08m",
        "outputId": "6e807e72-7179-434a-d661-1a2e849adec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  250M  100  250M    0     0  8680k      0  0:00:29  0:00:29 --:--:-- 9058k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  469M  100  469M    0     0  8961k      0  0:00:53  0:00:53 --:--:-- 9378k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  307k  100  307k    0     0   124k      0  0:00:02  0:00:02 --:--:--  124k\n",
            "Archive:  clickstream.zip\n",
            "  inflating: data/clickstream.csv    \n",
            "Archive:  transactions.zip\n",
            "  inflating: data/transactions.csv   \n",
            "  inflating: data/__MACOSX/._transactions.csv  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('data/transactions.csv'):\n",
        "    ! mkdir -p data\n",
        "    ! curl -OL https://storage.yandexcloud.net/datasouls-ods/materials/0433a4ca/transactions.zip\n",
        "    ! curl -OL https://storage.yandexcloud.net/datasouls-ods/materials/0554f0cf/clickstream.zip\n",
        "    ! curl -OL https://storage.yandexcloud.net/datasouls-ods/materials/e756bf99/train.csv\n",
        "    ! unzip clickstream.zip -d data\n",
        "    ! unzip transactions.zip -d data\n",
        "    ! cp train.csv data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eRKNDaz9Vks8"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import logging\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings('ignore')\n",
        "# logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HQedDuEFVna4",
        "outputId": "96665de7-7f63-4e19-81cf-2ef7b0e1862a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>mcc_code</th>\n",
              "      <th>currency_rk</th>\n",
              "      <th>transaction_amt</th>\n",
              "      <th>transaction_dttm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000932580e404dafbecd5916d4640938</td>\n",
              "      <td>5411</td>\n",
              "      <td>48</td>\n",
              "      <td>-361.07230</td>\n",
              "      <td>2020-08-03 08:05:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000932580e404dafbecd5916d4640938</td>\n",
              "      <td>5499</td>\n",
              "      <td>48</td>\n",
              "      <td>-137.31398</td>\n",
              "      <td>2020-08-05 01:27:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            user_id  mcc_code  currency_rk  transaction_amt  \\\n",
              "0  000932580e404dafbecd5916d4640938      5411           48       -361.07230   \n",
              "1  000932580e404dafbecd5916d4640938      5499           48       -137.31398   \n",
              "\n",
              "      transaction_dttm  \n",
              "0  2020-08-03 08:05:23  \n",
              "1  2020-08-05 01:27:40  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data_path = 'data/'\n",
        "\n",
        "source_data = pd.read_csv(os.path.join(data_path, 'transactions.csv'))\n",
        "source_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TklfcpgLYinv"
      },
      "outputs": [],
      "source": [
        "source_data.transaction_dttm = pd.to_datetime(source_data.transaction_dttm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wB2hy5fxVwp3"
      },
      "outputs": [],
      "source": [
        "from ptls.preprocessing import PandasDataPreprocessor\n",
        "\n",
        "preprocessor = PandasDataPreprocessor(\n",
        "    col_id='user_id',\n",
        "    col_event_time='transaction_dttm',\n",
        "    event_time_transformation='dt_to_timestamp',\n",
        "    cols_category=['mcc_code','currency_rk'],\n",
        "    cols_numerical=['transaction_amt'],\n",
        "    return_records=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lX13iRFXUhT",
        "outputId": "5e8e963f-9b9c-44f4-c858-3d348b353636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 25.8 s\n",
            "Wall time: 1min 7s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "dataset = preprocessor.fit_transform(source_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'user_id': '000932580e404dafbecd5916d4640938',\n",
              " 'event_time': tensor([1596441923, 1596590860, 1596598091, 1596674189, 1596933013, 1596935908,\n",
              "         1597016604, 1597030018, 1598297326, 1598492791, 1598579687, 1598588546,\n",
              "         1598682722, 1598763249, 1598827950, 1598906774, 1598919551, 1599007728,\n",
              "         1599011081, 1599090187, 1599164888, 1599187559, 1599337080, 1599343800,\n",
              "         1599690236, 1599691008, 1599807011, 1599807250, 1599807291, 1599812334,\n",
              "         1599838248, 1599877249, 1599880784, 1599961992, 1599974942, 1600029302,\n",
              "         1600216611, 1600295886, 1600395559, 1600397605, 1600583602, 1600591385,\n",
              "         1600634580, 1600648099, 1600669921, 1600726127, 1600738072, 1600807681,\n",
              "         1600823951, 1600981153, 1601002731, 1601006665, 1601006964, 1601010742,\n",
              "         1601109529, 1601263755, 1601340163, 1601344889, 1601353268, 1601423401,\n",
              "         1601433062, 1601526411, 1601607303, 1602015600, 1602015840, 1602037995,\n",
              "         1602102240, 1602199480, 1602201519, 1602209422, 1602273000, 1602295888,\n",
              "         1602297346, 1602300458, 1602300714, 1602304057, 1602304835, 1602385471,\n",
              "         1602386582, 1602392114, 1602465108, 1602479252, 1602504690, 1602541552,\n",
              "         1602565234, 1602568610, 1602641039, 1602647657, 1602711190, 1602725899,\n",
              "         1602971340, 1603016092, 1603142039, 1603163391, 1603232847, 1603246764,\n",
              "         1603322244, 1603325246, 1603400025, 1603406317, 1603418879, 1603419475,\n",
              "         1603419507, 1603425646, 1603583134, 1603586653, 1603657353, 1603661204,\n",
              "         1603679537, 1603755744, 1603764064, 1603857381, 1603860275, 1604176560,\n",
              "         1604176620, 1604181780, 1604198108, 1604538143, 1604539139, 1604545079,\n",
              "         1604546479, 1604615003, 1604628850, 1604634368, 1604780400, 1604954880,\n",
              "         1604957160, 1604961667, 1604967859, 1604967907, 1604972621, 1604975003,\n",
              "         1604976916, 1604990304, 1605131453, 1605177940, 1605740241, 1606009825,\n",
              "         1606176235, 1606356974, 1606882057, 1606882150, 1607038612, 1607041521,\n",
              "         1607043349, 1607045266, 1607309109, 1607324933, 1607572363, 1607576812,\n",
              "         1607577731, 1607579086, 1607581844, 1607643605, 1607656792, 1607751134,\n",
              "         1607831692, 1608091893, 1608094380, 1608175161, 1608176719, 1608185806,\n",
              "         1608186699, 1608268065, 1608324600, 1608328800, 1608342413, 1608347413,\n",
              "         1608348061, 1608348515, 1608351577, 1608408540, 1608417930, 1608423075,\n",
              "         1608423798, 1608430056, 1608438194, 1608606758, 1608611884, 1608614580,\n",
              "         1608670359, 1608673140, 1608707429, 1608708135, 1608709008, 1608757860,\n",
              "         1608760800, 1608859153, 1608862803, 1608892215, 1608933124, 1608935359,\n",
              "         1608938408, 1608940472, 1608945016, 1609020540, 1609028079, 1609029789,\n",
              "         1609040451, 1609196366, 1609198415, 1609202764, 1609206885, 1609210877,\n",
              "         1609308470, 1609381856, 1609489149, 1609801920, 1609803042, 1609819046,\n",
              "         1609825856, 1610050560, 1610056200, 1610221920, 1610567460, 1610571011,\n",
              "         1610599322, 1610614290, 1610679058, 1610753284, 1610758786, 1610777123,\n",
              "         1611007130, 1611029119, 1611527612, 1611637143, 1611701339, 1611714292,\n",
              "         1611785958, 1611811274, 1611909684, 1612129797, 1612140541, 1612142561,\n",
              "         1612144347, 1612146092, 1612146378, 1612150499, 1612744932, 1612915368,\n",
              "         1612925596, 1612927127, 1612927692, 1612937236, 1612938432, 1612940469,\n",
              "         1612999095, 1612999772, 1613003800, 1613004588, 1613007483, 1613008625,\n",
              "         1613040057, 1613083744, 1613088845, 1613096965, 1613181324, 1613185289,\n",
              "         1613187317, 1613346301, 1613350387, 1613353780, 1613368410, 1613441543,\n",
              "         1613455628, 1613513553, 1613518577, 1613797108, 1613802505, 1613903755,\n",
              "         1614045556, 1614050748, 1614113236, 1614113555, 1614127215, 1614216732,\n",
              "         1614218616, 1614224857, 1614237060, 1614302636, 1614303271, 1614311962,\n",
              "         1614323495, 1614543605, 1614561543, 1614565585, 1614570581, 1614631810,\n",
              "         1614635434, 1614651352, 1614723738, 1614740553, 1614742672, 1614828657,\n",
              "         1614828774, 1614831156, 1614889206, 1614924294, 1614927970, 1614939189,\n",
              "         1614993523, 1615074271, 1615079327, 1615081575, 1615082064, 1615084920,\n",
              "         1615087558, 1615183213, 1615189562, 1615238943, 1615248102, 1615248429,\n",
              "         1615253518, 1615255352, 1615258296, 1615325942, 1615329090, 1615331875,\n",
              "         1615337294, 1615352977, 1615408985, 1615420628, 1615425160, 1615426719,\n",
              "         1615497149, 1615498320, 1615509207, 1615510243, 1615513078, 1615515758,\n",
              "         1615520913, 1615523018, 1615526957, 1615604652, 1615606393, 1615688056,\n",
              "         1615692371, 1615696710, 1615709758, 1615771236, 1615775759, 1615801532,\n",
              "         1615842092, 1615845446, 1615867748, 1615926180, 1615948566, 1615953932,\n",
              "         1615956516, 1615962690, 1616019004, 1616100838, 1616118507, 1616125745,\n",
              "         1616147603, 1616359382, 1616372107, 1616372629, 1616377003, 1616387796,\n",
              "         1616450080, 1616462932, 1616550658, 1616551377, 1616563600, 1616625546,\n",
              "         1616630047, 1616630766, 1616633952, 1616635756, 1616636955, 1616805442,\n",
              "         1616811683, 1616819917, 1616819978, 1616919663, 1616994620, 1617058690,\n",
              "         1617074714, 1617139444, 1617152721, 1617153136, 1617155702, 1617164630,\n",
              "         1617165973, 1617167201, 1617168919, 1617184416, 1617229310, 1617234313,\n",
              "         1617253877, 1617313649, 1617319195, 1617321101, 1617327116, 1617337943,\n",
              "         1617421143, 1617424110, 1617487869, 1617488403, 1617491139, 1617494206,\n",
              "         1617498684, 1617502509, 1617505438, 1617508062, 1617513178, 1617651486,\n",
              "         1617658445, 1617660624, 1617666392, 1617666964, 1617672136, 1617686535,\n",
              "         1617686613, 1617743226, 1617774034, 1617775386, 1617823510, 1617832906,\n",
              "         1617845306, 1617854658, 1617856689, 1617914528, 1617924030, 1617924537,\n",
              "         1617925628, 1617940845, 1618010486, 1618208863, 1618264441, 1618289165,\n",
              "         1618290133, 1618293239, 1618302884, 1618354926, 1618361268, 1618364004,\n",
              "         1618365936, 1618433154, 1618440128, 1618440483, 1618450364, 1618451189,\n",
              "         1618463070, 1618516936, 1618518247, 1618540954, 1618549285, 1618561068,\n",
              "         1618620112, 1618620186, 1618623376, 1618636824, 1618711999, 1618712927,\n",
              "         1618722695, 1618793384, 1618809599, 1618816100, 1618868461, 1618869190,\n",
              "         1618953789, 1618960220, 1618967428, 1618984830, 1619035260, 1619037969,\n",
              "         1619062923, 1619121191, 1619129869, 1619155760, 1619207384, 1619215980,\n",
              "         1619231729, 1619235887, 1619244943, 1619320758, 1619328146, 1619328268,\n",
              "         1619380331, 1619397482, 1619398073, 1619410676, 1619411432, 1619411548,\n",
              "         1619412222, 1619413113, 1619416457, 1619493610, 1619494929, 1619551389,\n",
              "         1619567102, 1619567215, 1619582614, 1619596253, 1619645351, 1619651778,\n",
              "         1619723828, 1619736787, 1619764662, 1619773551, 1619815964, 1619817725,\n",
              "         1619817854, 1619818058, 1619820207, 1619898900, 1619899860, 1619983383,\n",
              "         1619991183, 1619992512, 1620012088, 1620014166, 1620016355, 1620020825,\n",
              "         1620105006, 1620181758, 1620182753, 1620183449, 1620264511, 1620266673,\n",
              "         1620274298, 1620354583, 1620358581, 1620359035, 1620430269, 1620502552,\n",
              "         1620529811, 1620534253, 1620534730, 1620540121, 1620607407, 1620611546,\n",
              "         1620673805, 1620690992, 1620693977, 1620707052, 1620707569, 1620766690,\n",
              "         1620774529, 1620777690, 1620778006, 1620778023, 1620792095, 1620851167,\n",
              "         1620882190, 1620935048, 1620946619, 1620951532, 1620954819, 1620964567,\n",
              "         1621002409, 1621117926, 1621123951, 1621124801, 1621125520, 1621126254,\n",
              "         1621126500, 1621131729, 1621137094, 1621193345, 1621220910, 1621222212,\n",
              "         1621280407, 1621281780, 1621302159, 1621391996, 1621398500, 1621403311,\n",
              "         1621453747, 1621468520, 1621481459, 1621490183, 1621502509, 1621547534,\n",
              "         1621551426, 1621562225, 1621566252, 1621573086, 1621574223, 1621587242,\n",
              "         1621655349, 1621655882, 1621666482, 1621667019, 1621667703, 1621721675,\n",
              "         1621722888, 1621723291, 1621748334, 1621798082, 1621809325, 1621832683,\n",
              "         1621834603, 1621886168, 1621975982, 1622004244, 1622063763, 1622067163,\n",
              "         1622072787, 1622076788, 1622077322, 1622084794, 1622092869, 1622151960,\n",
              "         1622156581, 1622156941, 1622161609, 1622161645, 1622162381, 1622164116,\n",
              "         1622164446, 1622165476, 1622166453, 1622167855, 1622169724, 1622231460,\n",
              "         1622231640, 1622236680, 1622237355, 1622264829, 1622268729, 1622346538,\n",
              "         1622408283, 1622408626, 1622420221, 1622426744, 1622436299, 1622439504,\n",
              "         1622488564, 1622508939, 1622527006, 1622576462, 1622608525, 1622609422,\n",
              "         1622668023, 1622749986, 1622764747, 1622766246, 1622779806, 1622780051,\n",
              "         1622862997, 1622863055, 1622864027, 1622950983, 1622952177, 1622961962,\n",
              "         1622962969, 1622963871, 1623007145, 1623019200, 1623039194, 1623043028,\n",
              "         1623097982, 1623117429, 1623122885, 1623132547, 1623137046, 1623184920,\n",
              "         1623196490, 1623208627, 1623208770, 1623232572, 1623272407, 1623281100,\n",
              "         1623286979, 1623291069, 1623315609, 1623354604, 1623362518, 1623372220,\n",
              "         1623380980, 1623466606, 1623544568, 1623544883, 1623545026, 1623550163,\n",
              "         1623553183, 1623554491, 1623647154, 1623647268, 1623786540, 1623791226,\n",
              "         1623799557, 1623876120, 1623879063, 1623889470, 1623893737, 1623893782,\n",
              "         1623901266, 1623969470, 1623974695, 1623975743, 1623990102, 1623992101,\n",
              "         1623996599, 1624078723, 1624144503, 1624146260, 1624146321, 1624147717,\n",
              "         1624151724, 1624151920, 1624154350, 1624245163, 1624246576, 1624246632,\n",
              "         1624311225, 1624334110, 1624389304, 1624407711, 1624414357, 1624417048,\n",
              "         1624484042, 1624486229, 1624507482, 1624508947, 1624580824, 1624675039,\n",
              "         1624748525, 1624765700, 1624769552, 1624772800, 1624774327, 1624820705,\n",
              "         1624826820, 1624828161, 1624851965, 1624858679, 1624861854, 1624863781,\n",
              "         1624915445, 1624920965, 1624923718, 1624928286, 1624928534, 1624935002,\n",
              "         1624948330, 1624950027, 1624956187, 1624999622, 1625010049, 1625013892,\n",
              "         1625029967, 1625080562, 1625093003, 1625098501, 1625101141, 1625109523,\n",
              "         1625109805, 1625118494, 1625175399, 1625188984, 1625201350, 1625284486,\n",
              "         1625367450, 1625426343, 1625450773, 1625453229, 1625520851, 1625526489,\n",
              "         1625542807, 1625605502, 1625629637, 1625707266, 1625792853, 1625793836,\n",
              "         1625796708, 1625797532, 1625808470, 1625860080, 1625867173, 1625870414,\n",
              "         1625871855, 1625872167, 1625875221, 1625875928, 1625876107, 1625880006,\n",
              "         1625887975, 1625899815, 1625900123, 1625900656, 1625902885, 1625958789,\n",
              "         1625959299, 1625965430, 1625982257, 1625983578, 1626046652, 1626125161,\n",
              "         1626213122, 1626220757, 1626236834, 1626296533, 1626297302, 1626300254,\n",
              "         1626301974, 1626314319, 1626316512, 1626396616, 1626412104, 1626412698,\n",
              "         1626475801, 1626565886, 1626572050, 1626589321, 1626597877, 1626651671,\n",
              "         1626663658, 1626749827, 1626833476, 1626854574, 1626900121, 1626909195,\n",
              "         1626998106, 1627003369, 1627081729, 1627086690, 1627185237, 1627186225,\n",
              "         1627188562, 1627203407, 1627243441, 1627333925, 1627357355, 1627362038,\n",
              "         1627362083, 1627413843, 1627426384, 1627452220, 1627505104, 1627519273,\n",
              "         1627532104, 1627537975, 1627586826, 1627597868, 1627607149, 1627607650,\n",
              "         1627609454, 1627690653, 1627693592, 1627693910, 1627695774]),\n",
              " 'mcc_code': tensor([  1,   2,   2,  13,   1,   3,  92,   1,   3,   1,  14,   1,   2,   1,\n",
              "           3,   3,   1,   2, 146,   1,   3,   1,   6,   4,   3,  11,   5,  81,\n",
              "           1,  13,   8,   1,   2,  14,   1,   3,  18,  72,   1,   1,   5,   1,\n",
              "          81,   3,  13,  72,   2,   3,   1,   3,   2,  33,  37,   2,   1,  33,\n",
              "           3,  13,   1,   3,  18, 146,   1,  17,  17, 146,  17,   3,  17,  13,\n",
              "          22,   2,   1,   1,   2,   2,   1,  33,   1,   6,  14,   1,  13,   3,\n",
              "           5,  13,   3,   1,   3,   2, 113,  13,   3,   1,   3,   1,   3,   3,\n",
              "           3,   3,   2,   1,   3,   1,   7, 146,   5,   3,  11,   3,   1,  33,\n",
              "           1,   2,   2,   1,   7,   1,   2,  33,  14,   3,  13,   5,   5,   9,\n",
              "           9,  13,  14,   1,   7,  33,   5,  13,   3,  13, 146,   7,   3,   1,\n",
              "           7,   7,  81,   7,   1,   3,   7,  13,   3,   5,   1,   1, 110, 146,\n",
              "           2,  14,  14,   1,   2,  14,  19,   1,   5,   5,  33, 146,  17,   5,\n",
              "          33, 107, 107,   5,   2,   1,   3,  14,   1,  49,   2,   1,   2,   3,\n",
              "          13,  17,  17,   2,   1,  13,  13,   8,  81,   1, 107,   2,   1,  48,\n",
              "          19,  14,   2,   1,  15,   2,  18,  18,   5,   2,  13,   1,   2,   1,\n",
              "           1, 146,   1,  92,  49,  20,  30,  13,   1,   3,   1,   4,  20,   2,\n",
              "           3, 146,   3,   2,   3,  19,   1,   3,  68,   1,  92,   7,   1,   2,\n",
              "           7,   5,   1,  57,   3, 146,  15,  15,   1,   7,   7,   3,  74,  33,\n",
              "          13,   9,   1,   9,   1,  14,   2,   7, 146,  57,   5,   1,   1,   3,\n",
              "         146,   9,   1,  13,  19,   1,   3,   3,  21,   2, 146,   9,   1,  21,\n",
              "          28,   9,   1,   9,  57,   9,   9,   9,   3,   2,   9,  17,   9,   1,\n",
              "          14,   5,   9,   1,   7,  13,  14,  23,   1,   9,   9,  19,  57,   9,\n",
              "           9,   9,  57,   9,   2,  28,   9,   9,  33,   2,   9,   1,   9,   1,\n",
              "           1,   7,   9,  14,   3,  44,   9,   5,   9,   1,   9,   1,   9,   9,\n",
              "           9,   9,   5,  13,   9,   8,   9,   9,   9,  73,   9,   9,   9,   9,\n",
              "           9,   9,  21,   9,  13,   9,   9,  37,   9,   9,   9,   9,   9,   9,\n",
              "           9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
              "           9,   9,   9, 146,   2,   9,  33,   9,  13,   8,   9,   3,   1,   3,\n",
              "          21,   3,  37,   9,   1,  14,  37,   9,  14,  14,   2,   9,   1,   3,\n",
              "           1,   9,   3,   3,  37,   3,   4,   3,   9,   9,   4,   1,   9,   3,\n",
              "          48,   2,   9,   9,   3,   3, 146,   9,   3,   9,   3,  19,   2,   9,\n",
              "           9,   3,  21,   9,   9,   1,   9,   5,   7,   7,   9,   9,   9,   9,\n",
              "           2,   9,  33,   1,  28,   1,   9,   3,   9,   3,   9,   9,   3,   9,\n",
              "           9,   7,   1,   9,  21,   9,   9,   9,   3,   9,   9, 146,   1,  17,\n",
              "           9,  81,   1,   1,   9,   3,  37,   9,   9,  65,  65,   9,   2,   1,\n",
              "           5,   9,   3,   3,   2,   9,   9,   3,   9,   3,   5,   1,   1,   1,\n",
              "          23,   2,   2,   6,   6,   9,   9,   9,  23,   9,   5,   9,   4,   9,\n",
              "          28,   1,  23,   2,   1,  52,   9,   2,  43,   9,   9,   9,   9,   2,\n",
              "          43,  30,   9,   3,   3,  23,  23,   9,   3,   3,   3,   1,   5,   9,\n",
              "           9,   9,   3,  13,   5,   1,   8,   9,  28,   1,  33,   2,  57,   9,\n",
              "          13,   9,   9,   1,   9,  21,  21,   1,   9,   1,   9,   1,   1,   9,\n",
              "          13,   3,   3,   1,   9,   9,   1,   9,   2,   9,  33,  28,   9,  14,\n",
              "           5,   1,   1,   9,   3,   1,   3,   9,   9,   9,   9,  28,  28,   3,\n",
              "         146,  52,   9,  21, 146,   2,   3,   1,   1,  57,   9,  33,   1, 146,\n",
              "         146,   9,  14,   9,  23,   9,   9,   3,   9,  28,  37,   5,   2,   1,\n",
              "           9,   1,   9,   9,   7,   9,   9,   9,   1,   1,   1,   9,   1,   3,\n",
              "           1,   9,  13,   9,   2,   1,   9,   3,   1,   9,   9,   9,   2,   1,\n",
              "           1,  21,  37,   9,   2,  13,   9,  52,   3,   9,   1,   9,   3,  19,\n",
              "           1,   1,   1,  28,  33,   5,   1,   5,   2,   2,  21,   9,   3,  21,\n",
              "           9,   3,  33,  57,   9,   1,   5,   3,   1,   9,   2,   1,   9,  23,\n",
              "          28,  23,   2,  57,   9,   3,  23,  28,  28,   9,   9,   3,   2,   1,\n",
              "           9,  28,   2,   1,   9,   5,   5, 146,   1,   2,   9,   9,  37,  28,\n",
              "           9,   2, 146, 146,   9,  21,  33,   3,  33,   9,   1,  14,  13,   9,\n",
              "           3,   3,   2,   9,  28,   9,   9,  28,  33,   1,   9,   9,   9,   1,\n",
              "           2,   9,   3, 146,   9,   5,   2,   9,   2, 146,   9,  53,   1,   9,\n",
              "           1,  14,   9,   9,   9,  44,   9,   9,   9,  15,   1,   9,   9,   9,\n",
              "           9,   1,  23,  23,   9,   9,   1,   9,   9,  28,   2,   1,   9,  92,\n",
              "           1,   1,   5,  13,  56,  28,   9,   1,   9,   7,   1,   5,   2,   1,\n",
              "           1,  13,   9,   9,   1,   1,   1,   2,   1,   1,  14,   8,   9,   9,\n",
              "           3,   2,  28,   9,   9,   1,   9,   1,   1,  23,   9,   5,   2,   1,\n",
              "          28,  77,  16,   5,  16]),\n",
              " 'currency_rk': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1]),\n",
              " 'transaction_amt': tensor([-3.6107e+02, -1.3731e+02, -1.3885e+02, -3.0948e+02, -1.3347e+02,\n",
              "         -6.3415e+01, -1.6403e+03, -1.4979e+03, -1.7712e+02, -9.5083e+01,\n",
              "         -5.6271e+02, -1.9984e+02, -4.6031e+02, -1.1324e+02, -1.6919e+02,\n",
              "         -3.4814e+01, -1.9616e+02, -9.8234e+01, -1.6116e+02, -4.3518e+02,\n",
              "         -5.8619e+01, -2.0905e+02, -1.1332e+03, -3.5493e+02, -6.2905e+01,\n",
              "         -6.6878e+01, -5.6401e+02, -3.0178e+02, -3.2649e+02,  1.3260e+03,\n",
              "          2.7035e+00, -2.0304e+02, -4.9185e+02, -1.3286e+02, -1.2123e+02,\n",
              "         -1.0408e+02, -2.4339e+02, -7.2862e+02, -1.9233e+02, -1.8085e+02,\n",
              "         -1.6481e+03, -4.1420e+02, -1.1554e+04, -1.0819e+02,  9.1249e+02,\n",
              "         -4.2950e+02, -7.4400e+01, -5.9363e+01, -2.0186e+02, -3.5392e+01,\n",
              "         -6.5554e+01, -1.4695e+02, -1.2737e+02, -5.9989e+01, -3.5871e+02,\n",
              "         -7.8752e+01, -5.5038e+01,  1.0705e+03, -2.5870e+02, -6.6037e+01,\n",
              "         -2.3650e+02, -1.2975e+03, -2.9183e+02, -2.1551e+03, -2.6712e+03,\n",
              "         -3.7768e+02,  1.1179e+03, -3.8168e+02, -1.6255e+02,  3.3055e+03,\n",
              "         -2.9952e+04, -7.5687e+02, -2.1745e+02, -1.3930e+02, -1.2729e+02,\n",
              "         -1.9867e+02, -2.5433e+03, -8.9567e+02, -3.3857e+02, -1.0830e+03,\n",
              "         -3.3256e+02, -2.9221e+02,  4.2307e+02, -1.3985e+02,  3.4175e+04,\n",
              "          4.4660e+01, -1.0548e+02, -1.8912e+02, -1.2565e+02, -3.2180e+02,\n",
              "         -2.8902e+03,  1.1418e+03, -1.1974e+02, -4.7376e+01, -1.2291e+02,\n",
              "         -6.7704e+01, -2.2218e+02, -2.0830e+02, -1.4226e+01, -9.0696e+01,\n",
              "         -3.9775e+02, -8.9735e+01, -2.9067e+02, -2.8956e+02, -4.1388e+02,\n",
              "         -6.8476e+02, -5.0374e+03, -2.0578e+02, -1.5058e+02, -5.3711e+01,\n",
              "         -1.7640e+02, -1.6773e+03, -6.9644e+02, -3.3733e+02, -1.1704e+02,\n",
              "         -3.0488e+03, -1.0378e+02, -9.1612e+01, -1.0135e+02, -1.0468e+02,\n",
              "         -1.4026e+02, -1.6322e+02, -3.7719e+02, -1.3669e+03, -4.6203e+03,\n",
              "         -2.3990e+01, -2.9561e+01,  5.0841e+03, -9.6800e+01, -2.8292e+01,\n",
              "         -4.0444e+02, -7.6556e+01, -2.1445e+02,  1.5323e+02, -1.3649e+02,\n",
              "          5.4168e+03, -8.1199e+02, -4.2759e+02, -1.9526e+02, -6.0628e+02,\n",
              "         -2.4774e+02, -1.7173e+03, -1.5315e+02, -1.3822e+02, -1.9431e+02,\n",
              "         -1.8488e+02, -5.7983e+02,  1.8894e+03, -1.5818e+02, -3.6487e+02,\n",
              "         -1.1762e+03, -2.5616e+02, -1.2757e+03, -9.6577e+02, -5.3260e+02,\n",
              "         -2.8970e+02, -4.1209e+03, -2.4722e+02, -2.0763e+02, -3.7815e+02,\n",
              "         -2.6434e+02, -6.5681e+02, -6.4203e+02, -6.7947e+02, -6.3638e+02,\n",
              "         -8.6954e+03, -8.4604e+02, -2.1372e+02, -2.9038e+02, -1.7462e+02,\n",
              "         -3.7567e+02, -1.0684e+03, -2.6023e+02, -1.5867e+02, -5.1880e+01,\n",
              "         -1.2219e+02, -7.9313e+02, -6.3633e+01, -1.2705e+02, -6.8422e+02,\n",
              "         -2.3131e+02, -1.3280e+02,  5.5846e+03, -1.2081e+02, -1.9876e+02,\n",
              "         -6.5739e+02, -5.5309e+02,  8.1933e-01,  1.6463e+04,  8.6538e+02,\n",
              "         -6.3467e+02, -4.1989e+02, -3.7580e+03, -4.9042e+02, -9.3709e+02,\n",
              "         -2.1198e+03, -4.6498e+02, -3.3960e+02, -2.1451e+02, -2.9544e+02,\n",
              "         -6.0558e+02, -2.0916e+02, -6.3629e+01, -3.9399e+02, -4.6834e+02,\n",
              "         -4.9199e+02,  6.2132e+03, -3.7155e+02, -8.3514e+01, -1.0264e+03,\n",
              "         -4.7000e+01, -4.1521e+02, -1.6307e+03, -1.5918e+02, -1.7310e+03,\n",
              "         -7.4926e+02, -2.8516e+04,  2.7699e+03, -9.4417e+02, -2.5436e+02,\n",
              "         -9.8122e+02, -3.0204e+02, -5.8605e+02, -1.6777e+02, -7.1048e+02,\n",
              "         -7.2414e+02, -7.4960e+02, -2.4691e+02, -1.3047e+02, -1.5959e+02,\n",
              "         -7.9086e+02, -2.8992e+01, -4.3380e+02, -2.5261e+02, -3.5368e+02,\n",
              "         -7.4791e+01, -5.2150e+02, -4.0828e+02, -7.0362e+01, -1.8828e+03,\n",
              "         -1.0882e+02, -2.9727e+02, -1.1711e+02, -4.5765e+02, -2.2426e+02,\n",
              "         -1.8277e+02, -1.2388e+02, -2.4088e+02, -7.9315e+01, -6.3303e+01,\n",
              "         -2.1966e+02, -1.0159e+02,  2.6718e+03, -3.0477e+01, -5.4030e+02,\n",
              "         -3.0104e+01, -8.3094e+02, -1.0009e+02, -2.0626e+02, -4.4851e+02,\n",
              "         -7.7575e+02, -7.6841e+01,  9.4543e+03, -3.0738e+02, -1.4097e+02,\n",
              "         -5.6456e+01, -3.4437e+02, -2.6577e+01, -1.3114e+02,  2.8740e+03,\n",
              "         -2.7605e+01, -2.8296e+02, -7.4648e+01, -2.3497e+02, -1.2963e+03,\n",
              "         -1.7455e+02, -1.3951e+02, -2.9641e+01, -8.1871e+01, -1.4028e+03,\n",
              "         -1.1691e+02, -2.9869e+01, -2.7663e+02, -2.3985e+01, -2.0309e+02,\n",
              "         -2.2414e+01, -2.2481e+01, -2.1267e+01, -4.6230e+01, -1.7338e+02,\n",
              "         -2.4531e+01, -5.5243e+01, -2.4879e+01, -6.3983e+02, -1.2699e+02,\n",
              "         -6.6157e+02, -2.1286e+01, -3.1203e+02, -4.9416e+02,  2.7047e+03,\n",
              "         -1.1332e+03, -4.1508e+02, -2.2651e+02, -2.0357e+01, -2.5128e+01,\n",
              "         -1.8040e+02, -1.2114e+02, -2.1273e+01, -2.0475e+01, -2.4447e+01,\n",
              "         -1.9176e+02, -2.4744e+01, -3.2935e+02, -1.2379e+02, -2.4332e+01,\n",
              "         -2.5413e+01, -1.6808e+02, -1.8592e+02, -2.5127e+01, -3.7555e+02,\n",
              "         -2.1664e+01, -2.2138e+02, -7.1797e+01, -8.8879e+01, -2.2002e+01,\n",
              "         -3.7541e+02, -5.4469e+01, -7.4321e+01, -2.4573e+01, -1.8914e+03,\n",
              "         -2.4834e+01, -2.0931e+02, -2.4720e+01, -8.8244e+02, -2.0288e+01,\n",
              "         -2.1034e+01, -2.1775e+01, -2.2337e+01,  1.2215e+04,  8.0705e+02,\n",
              "         -2.0869e+01,  9.0209e+02, -2.0728e+01, -2.2510e+01, -2.1658e+01,\n",
              "         -2.8875e+04, -2.4739e+01, -2.4534e+01, -2.1781e+01, -2.1308e+01,\n",
              "         -2.1471e+01, -2.1329e+01, -6.6207e+02, -2.5108e+01,  5.5657e+03,\n",
              "         -2.1714e+01, -2.5628e+01, -1.7496e+02, -2.3921e+01, -2.2112e+01,\n",
              "         -2.2395e+01, -2.1160e+01, -2.3858e+01, -2.1572e+01, -2.0927e+01,\n",
              "         -2.4191e+01, -2.2441e+01, -2.0784e+01, -2.5599e+01, -2.0501e+01,\n",
              "         -2.1782e+01, -2.1221e+01, -2.0672e+01, -2.1367e+01, -2.5633e+01,\n",
              "         -2.5009e+01, -2.5098e+01, -2.1897e+01, -2.1628e+01, -2.4561e+01,\n",
              "         -2.3704e+01, -2.3385e+02, -3.7972e+02, -2.1184e+01, -1.7432e+02,\n",
              "         -2.4572e+01,  2.6104e+04,  2.5195e+02, -2.5064e+01, -3.4841e+02,\n",
              "         -9.2891e+01, -8.0280e+01, -8.0418e+02, -1.1711e+02, -2.1530e+02,\n",
              "         -2.1080e+01, -6.6830e+02, -7.7974e+02, -2.3605e+02, -2.0670e+01,\n",
              "         -4.5965e+02, -1.3246e+02, -1.0420e+03, -2.5318e+01, -1.1032e+01,\n",
              "         -1.0053e+02, -4.7576e+02, -2.0589e+01, -3.5319e+01, -9.9239e+00,\n",
              "         -1.8205e+02, -1.0441e+02, -6.1838e+02, -9.2623e+01, -2.0741e+01,\n",
              "         -2.0484e+01, -3.3596e+02, -1.0604e+03, -2.4838e+01, -9.6511e+01,\n",
              "         -2.7954e+03, -3.8193e+02, -2.0837e+01, -2.5482e+01, -6.3216e+01,\n",
              "         -1.2119e+02, -4.2779e+02, -2.1798e+01, -1.2601e+02, -2.5460e+01,\n",
              "         -1.1675e+02, -5.5684e+01, -3.2181e+02, -2.4311e+01, -2.5427e+01,\n",
              "         -2.1665e+02, -1.8993e+03, -2.0300e+01, -2.1281e+01, -3.0048e+02,\n",
              "         -2.1314e+01, -2.7212e+02, -2.5280e+02, -1.7037e+02, -2.1239e+01,\n",
              "         -2.5019e+01, -2.0836e+01, -2.4697e+01, -3.2370e+02, -2.6485e+01,\n",
              "         -2.0502e+02, -4.1811e+01, -1.7794e+02, -2.2392e+02, -2.0218e+01,\n",
              "         -5.7745e+02, -2.1583e+01, -6.1052e+01, -2.4841e+01, -2.1090e+01,\n",
              "         -1.0704e+02, -2.1486e+01, -2.2253e+01, -1.1777e+03, -7.4378e+01,\n",
              "         -2.4192e+01, -1.9767e+03, -2.0666e+01, -2.0031e+01, -2.3791e+01,\n",
              "         -1.6798e+02, -2.4362e+01, -2.6809e+01, -6.1373e+02, -6.0813e+02,\n",
              "         -1.0296e+01, -2.4974e+01, -3.0951e+01, -4.4515e+02, -4.9566e+01,\n",
              "         -2.5444e+01, -8.4939e+01, -3.5689e+02, -2.4708e+01, -2.1811e+01,\n",
              "         -3.9634e+02, -1.4786e+01, -2.4027e+01, -6.0177e+01, -4.8822e+02,\n",
              "         -1.8916e+03, -2.0344e+01, -3.6411e+01, -6.8056e+01, -4.5950e+02,\n",
              "         -2.1980e+01, -2.4604e+01, -1.1601e+02, -2.5123e+01, -1.6688e+02,\n",
              "         -1.6598e+04, -3.6707e+02, -4.2711e+02, -1.4754e+02, -2.8456e+02,\n",
              "         -8.5553e+01, -1.9548e+02, -1.2601e+04, -1.8927e+04, -2.5174e+01,\n",
              "         -2.4319e+01, -2.2531e+01, -6.3986e+02, -2.1103e+01, -4.6268e+02,\n",
              "         -2.5448e+01, -4.8471e+02, -2.4492e+01, -5.2579e+01, -5.9907e+02,\n",
              "         -1.8381e+02, -5.4504e+02, -4.1996e+02, -3.9419e+01, -2.5752e+01,\n",
              "         -7.2016e+01, -1.6393e+03, -2.8044e+01, -2.0241e+01, -2.4580e+01,\n",
              "         -2.1013e+01, -5.4622e+01, -9.9589e+00, -3.4705e+02, -2.1786e+01,\n",
              "         -4.3302e+01, -4.0655e+02, -1.9914e+02, -4.1673e+02, -2.4016e+01,\n",
              "         -1.4501e+02, -4.0441e+01, -1.2078e+02, -2.7375e+02,  3.6450e+04,\n",
              "         -2.5287e+01, -2.4532e+01, -2.1082e+01, -4.1230e+01,  2.8163e+02,\n",
              "          1.2757e+04, -1.3844e+03,  4.6720e+02, -2.5019e+01, -9.6845e+01,\n",
              "         -2.3277e+02, -2.7665e+02, -8.4103e+02, -2.8591e+02, -2.5091e+01,\n",
              "          2.1404e+03, -2.2348e+01, -2.1586e+01, -2.4178e+02, -2.0690e+01,\n",
              "         -3.4676e+03, -2.2792e+03, -2.6372e+02, -2.0787e+01, -3.3807e+02,\n",
              "         -2.4165e+01, -1.6926e+02, -5.9837e+01, -2.5275e+01,  2.9737e+03,\n",
              "         -4.9277e+01, -6.9091e+01, -1.3109e+02, -2.2590e+01, -2.1935e+01,\n",
              "         -7.7865e+01, -2.5042e+01, -1.2286e+02, -2.1368e+01, -4.2759e+02,\n",
              "         -7.9905e+01, -2.3843e+01, -1.5418e+02, -1.2137e+03, -4.4115e+01,\n",
              "         -6.6199e+02, -2.4535e+01, -8.2271e+01, -7.6194e+02, -8.8321e+01,\n",
              "         -2.5924e+01, -2.5398e+01, -2.0032e+01, -2.5752e+01, -8.3698e+01,\n",
              "         -8.7537e+01, -1.6824e+02, -7.9186e+02, -1.0986e+02, -2.5028e+01,\n",
              "         -6.7931e+03, -3.8378e+02, -1.0496e+02, -1.6088e+02, -1.1743e+02,\n",
              "         -9.3012e+01, -3.1187e+02, -2.1737e+01, -1.7348e+02, -1.6494e+03,\n",
              "          8.4824e+02,  7.8039e+02, -2.7064e+01, -1.4386e+04, -3.1645e+01,\n",
              "         -1.9481e+02, -2.4478e+01, -2.5302e+01, -2.9326e+02, -2.0843e+01,\n",
              "         -7.8726e+01, -9.3898e+01,  4.6593e+03, -4.0130e+01, -3.2000e+02,\n",
              "         -2.0918e+01, -1.5232e+02, -2.5121e+01, -2.5918e+01, -5.6348e+02,\n",
              "         -2.4480e+01, -2.0876e+01, -2.1498e+01, -4.5357e+02, -6.4135e+02,\n",
              "         -2.7895e+02, -2.5636e+01, -5.5534e+02, -3.7748e+02, -4.1306e+02,\n",
              "         -2.4038e+01,  2.4370e+03, -2.4335e+01, -1.5277e+02, -2.8557e+02,\n",
              "         -2.1080e+01, -1.5420e+02, -2.0005e+02, -2.4291e+01, -2.2167e+01,\n",
              "         -2.0685e+01, -1.6778e+02, -1.9628e+02, -1.0958e+02, -5.4829e+03,\n",
              "         -5.5342e+01, -2.0795e+01, -2.9934e+02,  4.4622e+02, -2.3409e+01,\n",
              "         -6.3694e+01, -1.8030e+02, -2.1975e+01, -1.1823e+02, -2.1240e+01,\n",
              "         -6.0067e+01, -5.4200e+01, -2.0470e+02, -8.8706e+02, -6.5183e+01,\n",
              "         -9.8018e+01, -1.8163e+02, -5.2536e+03, -7.1647e+02,  2.3725e+04,\n",
              "         -1.2469e+02, -2.1447e+02, -3.0637e+03, -2.4109e+01, -2.4229e+02,\n",
              "          3.5793e+03, -2.0826e+01, -8.2336e+01, -9.1514e+01, -2.1060e+02,\n",
              "         -2.2008e+01, -2.2855e+02, -3.6362e+02, -1.1862e+02, -3.8334e+02,\n",
              "         -1.9954e+01, -1.7636e+02, -5.4865e+02, -2.0394e+01, -5.0798e+02,\n",
              "         -1.8085e+02, -3.7765e+01, -3.9718e+02, -2.8748e+02, -2.1452e+01,\n",
              "         -7.3027e+02, -6.4049e+02, -1.2551e+02, -6.3079e+01, -2.0223e+01,\n",
              "         -2.5703e+01, -8.7811e+01, -3.0105e+02, -8.5491e+01, -2.1306e+01,\n",
              "         -1.3527e+02, -5.5385e+02, -5.8530e+02, -2.5585e+01, -2.1732e+02,\n",
              "         -1.3734e+03, -4.8685e+02, -1.2041e+02, -1.3757e+02, -2.4997e+01,\n",
              "         -2.4974e+01, -9.4927e+01, -7.7693e+01, -2.1598e+01, -2.1777e+02,\n",
              "         -1.3468e+03, -2.6904e+02, -2.1143e+01, -2.2992e+02, -2.1133e+02,\n",
              "         -9.6870e+01, -1.1865e+02, -2.3825e+01, -4.4601e+02, -1.3156e+02,\n",
              "          1.1489e+03, -2.1548e+01, -2.9571e+02, -1.4818e+02, -2.2305e+02,\n",
              "         -3.0122e+01, -3.7464e+01, -3.1426e+01, -3.2052e+01, -3.6679e+02,\n",
              "         -6.2779e+01, -5.6371e+02, -4.1242e+01, -3.1945e+01, -2.7916e+01,\n",
              "         -3.7367e+02, -4.1621e+02, -3.0208e+01, -1.2394e+02, -1.2607e+03,\n",
              "         -2.6563e+01, -1.0880e+02, -2.7820e+02, -3.1652e+01, -2.4788e+02,\n",
              "         -1.0251e+03, -3.6270e+01, -8.5658e+02, -6.6646e+02, -3.6315e+01,\n",
              "         -1.2678e+02, -1.1857e+03, -3.2371e+01, -3.7056e+01, -3.3111e+01,\n",
              "         -2.1921e+02, -3.2201e+01, -3.6826e+01, -3.2629e+01, -3.4987e+02,\n",
              "         -9.3274e+02, -3.1568e+01, -3.3029e+01, -3.3605e+01, -3.1870e+01,\n",
              "         -3.2229e+02, -1.4878e+02, -5.2829e+02, -3.1944e+01, -3.7885e+01,\n",
              "         -8.8450e+02, -3.0877e+01, -3.1416e+01, -1.7523e+02, -3.9646e+02,\n",
              "         -5.8249e+01, -2.9856e+01, -9.0026e+01, -8.2080e+01, -4.3849e+02,\n",
              "         -2.1962e+03,  2.1091e+03, -4.3663e+01, -2.0411e+02, -2.8168e+01,\n",
              "         -1.0324e+02, -2.8579e+01, -1.5699e+02, -3.6570e+02, -4.5974e+02,\n",
              "         -8.6372e+02, -1.8929e+03, -9.7248e+01,  2.1784e+03, -3.0415e+01,\n",
              "         -2.7859e+01, -3.2078e+02, -8.8711e+01, -5.6109e+02, -1.4929e+02,\n",
              "         -4.9882e+02, -9.8764e+01, -1.5750e+02,  5.8636e+02, -2.6875e+01,\n",
              "         -2.5467e+01, -2.0622e+02, -1.5436e+02, -1.8279e+02, -2.6594e+01,\n",
              "         -3.1584e+01, -3.7810e+02, -2.6363e+01, -3.1358e+02, -1.4964e+03,\n",
              "         -1.5661e+02, -3.1967e+01, -3.6034e+02, -1.2736e+03, -3.6023e+02,\n",
              "         -1.3077e+02, -6.6747e+01, -2.3075e+01, -1.0591e+03, -2.8339e+01],\n",
              "        dtype=torch.float64)}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PzrJpndVYElQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('preprocessor.p', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z1a9YCiSZ3ua"
      },
      "outputs": [],
      "source": [
        "dataset = sorted(dataset, key=lambda x: x['user_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq6NZuxGaNlH",
        "outputId": "b524c83a-8401-4c31-be28-ff772a5ab46f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18026, 4507)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "len(train), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zFSInr_jairD"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
        "from ptls.frames.coles import CoLESModule\n",
        "\n",
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.003,\n",
        "    numeric_values={'transaction_amt': 'identity'},\n",
        "    embeddings={\n",
        "        'event_time': {'in': 800, 'out': 16},\n",
        "        'mcc_code': {'in': 600, 'out': 16},\n",
        "        'currency_rk':{'in': 4, 'out': 2}\n",
        "    },\n",
        ")\n",
        "\n",
        "seq_encoder = RnnSeqEncoder(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    hidden_size=256,\n",
        "    type='gru',\n",
        ")\n",
        "\n",
        "model = CoLESModule(\n",
        "    seq_encoder=seq_encoder,\n",
        "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
        "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_VIVs-aOfUSS"
      },
      "outputs": [],
      "source": [
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames.coles import ColesDataset\n",
        "from ptls.frames.coles.split_strategy import SampleSlices\n",
        "from ptls.frames import PtlsDataModule\n",
        "\n",
        "train_dl = PtlsDataModule(\n",
        "    train_data=ColesDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=train,\n",
        "            i_filters=[\n",
        "                SeqLenFilter(min_seq_len=25),\n",
        "            ],\n",
        "        ),\n",
        "        splitter=SampleSlices(\n",
        "            split_count=5,\n",
        "            cnt_min=25,\n",
        "            cnt_max=200,\n",
        "        ),\n",
        "    ),\n",
        "    train_num_workers=2,\n",
        "    train_batch_size=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CzMw21FfmVS",
        "outputId": "eae86b10-d9a2-4340-be3c-c8eca82831c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import logging\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    enable_progress_bar=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtz3PI1Tfo2o",
        "outputId": "cdedfdb1-56a3-45fa-ed49-02d00dfe0cb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params\n",
            "-------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0     \n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 247 K \n",
            "2 | _validation_metric | BatchRecallTopK | 0     \n",
            "3 | _head              | Head            | 0     \n",
            "-------------------------------------------------------\n",
            "247 K     Trainable params\n",
            "0         Non-trainable params\n",
            "247 K     Total params\n",
            "0.991     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': tensor(136.1643), 'seq_len': tensor(116.4000)}\n",
            "CPU times: user 4min 1s, sys: 17.6 s, total: 4min 19s\n",
            "Wall time: 5min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XEtoi7Sigm9s"
      },
      "outputs": [],
      "source": [
        "torch.save(seq_encoder.state_dict(), \"coles-emb.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIVQTu-Sgom5",
        "outputId": "e2d5877b-8709-461a-bed6-7a4ea65cdd75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:175: UserWarning: Lightning couldn't infer the indices fetched for your dataloader.\n",
            "  warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")\n",
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([18026, 256]), torch.Size([4507, 256]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ptls.data_load.datasets import inference_data_loader\n",
        "\n",
        "train_dl = inference_data_loader(train, num_workers=0, batch_size=256)\n",
        "train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
        "\n",
        "test_dl = inference_data_loader(test, num_workers=0, batch_size=256)\n",
        "test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
        "\n",
        "train_embeds.shape, test_embeds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8rpKpMygp06",
        "outputId": "e417878c-989f-4af2-b633-c2c79af3996f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18026, 258) (4507, 258)\n"
          ]
        }
      ],
      "source": [
        "df_target = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "df_target.rename(columns={'bank':'user_id'},inplace=True)\n",
        "df_target = df_target.set_index('user_id')\n",
        "df_target.rename(columns={\"bins\": \"target\"}, inplace=True)\n",
        "\n",
        "train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
        "train_df['user_id'] = [x['user_id'] for x in train]\n",
        "train_df = train_df.merge(df_target, how='left', on='user_id')\n",
        "\n",
        "test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
        "test_df['user_id'] = [x['user_id'] for x in test]\n",
        "\n",
        "test_df = test_df.merge(df_target, how='left', on='user_id')\n",
        "\n",
        "print(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vRDh_R9YnYtw"
      },
      "outputs": [],
      "source": [
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jL48QC1gsed",
        "outputId": "0c30ba33-b168-475a-bdfb-865fa3e9eb3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7743865948533812"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
        "x_train, y_train = train_df[embed_columns], train_df['higher_education']\n",
        "x_test, y_test = test_df[embed_columns], test_df['higher_education']\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRz7MqIRiJNN"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
        "from ptls.frames.coles import CoLESModule\n",
        "\n",
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.003,\n",
        "    numeric_values={'transaction_amt': 'identity'},\n",
        "    embeddings={\n",
        "        'event_time': {'in': 800, 'out': 16},\n",
        "        'mcc_code': {'in': 600, 'out': 16},\n",
        "        'currency_rk':{'in': 4, 'out': 2}\n",
        "    },\n",
        ")\n",
        "\n",
        "seq_encoder = RnnSeqEncoder(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    hidden_size=129,\n",
        "    type='gru',\n",
        ")\n",
        "\n",
        "model = CoLESModule(\n",
        "    seq_encoder=seq_encoder,\n",
        "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
        "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
        ")\n",
        "\n",
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames.coles import ColesDataset\n",
        "from ptls.frames.coles.split_strategy import SampleSlices\n",
        "from ptls.frames import PtlsDataModule\n",
        "\n",
        "train_dl = PtlsDataModule(\n",
        "    train_data=ColesDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=train,\n",
        "            i_filters=[\n",
        "                SeqLenFilter(min_seq_len=25),\n",
        "            ],\n",
        "        ),\n",
        "        splitter=SampleSlices(\n",
        "            split_count=5,\n",
        "            cnt_min=25,\n",
        "            cnt_max=200,\n",
        "        ),\n",
        "    ),\n",
        "    train_num_workers=2,\n",
        "    train_batch_size=256,\n",
        ")\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import logging\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    enable_progress_bar=False,\n",
        ")\n",
        "\n",
        "%%time\n",
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model, train_dl)\n",
        "print(trainer.logged_metrics)\n",
        "\n",
        "from ptls.data_load.datasets import inference_data_loader\n",
        "\n",
        "train_dl = inference_data_loader(train, num_workers=0, batch_size=256)\n",
        "train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
        "\n",
        "test_dl = inference_data_loader(test, num_workers=0, batch_size=256)\n",
        "test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
        "\n",
        "train_embeds.shape, test_embeds.shape\n",
        "\n",
        "df_target = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "df_target.rename(columns={'bank':'user_id'},inplace=True)\n",
        "df_target = df_target.set_index('user_id')\n",
        "df_target.rename(columns={\"bins\": \"target\"}, inplace=True)\n",
        "\n",
        "train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
        "train_df['user_id'] = [x['user_id'] for x in train]\n",
        "train_df = train_df.merge(df_target, how='left', on='user_id')\n",
        "\n",
        "test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
        "test_df['user_id'] = [x['user_id'] for x in test]\n",
        "test_df = test_df.merge(df_target, how='left', on='user_id')\n",
        "\n",
        "print(train_df.shape, test_df.shape)\n",
        "\n",
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
        "x_train, y_train = train_df[embed_columns], train_df['higher_education']\n",
        "x_test, y_test = test_df[embed_columns], test_df['higher_education']\n",
        "\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier, metrics\n",
        "CatBoostModel = CatBoostClassifier(\n",
        "iterations= 500,\n",
        "learning_rate = 0.05,\n",
        "use_best_model = True,\n",
        "eval_metric ='F1', \n",
        "loss_function='Logloss',\n",
        "random_seed = 42,\n",
        "logging_level = 'Silent',\n",
        "depth = 5)\n",
        "\n",
        "CatBoostModel.fit(\n",
        "    x_train, y_train,\n",
        "    eval_set=(x_test, y_test),\n",
        "    plot=True\n",
        "#     logging_level='Verbose',  # you can uncomment this for text output\n",
        ")\n",
        "\n",
        "CatBoostModel.get_best_score()\n",
        "\n",
        "y_pred = CatBoostModel.predict(x_test)\n",
        "y_proba = CatBoostModel.predict_proba(x_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "print(f'''accuracy: {CatBoostModel.score(x_test, y_test)} \n",
        "      f1: {f1_score(y_pred, y_test)}, \n",
        "      precision: {precision_score(y_pred, y_test)}\n",
        "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
