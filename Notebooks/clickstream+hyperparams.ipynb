{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iwQZIUyHcRT5",
    "outputId": "12475af0-16ad-4084-b8f6-a1ddc6ac63e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.0.0-py3-none-any.whl (715 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.6/715.6 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (6.0)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.22.4)\n",
      "Collecting lightning-utilities>=0.7.0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2023.3.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.13.1+cu116)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.65.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
      "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, torchmetrics, aiosignal, aiohttp, pytorch_lightning\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.0 torchmetrics-0.11.4 yarl-1.8.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-lifestream\n",
      "  Downloading pytorch-lifestream-0.5.2.tar.gz (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lifestream) (9.0.0)\n",
      "Collecting transformers==4.*\n",
      "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hydra-core>=1.1.2\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning==1.6.*\n",
      "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 KB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (23.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (0.11.4)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (3.19.6)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (2023.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (1.13.1+cu116)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning==1.6.*->pytorch-lifestream) (6.0)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.*->pytorch-lifestream) (3.10.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting omegaconf<2.4,>=2.2\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.8.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.16.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (67.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.4.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.40.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.51.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.*->pytorch-lifestream) (1.26.15)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.8.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.*->pytorch-lifestream) (3.2.2)\n",
      "Building wheels for collected packages: pytorch-lifestream, antlr4-python3-runtime\n",
      "  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.5.2-py3-none-any.whl size=256980 sha256=fa4bcb00e6aa23a69327a8599d9f5d9da7620d30d5e8405de55f132d2a51ed96\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/3c/f7/565354c0a36c9f9cd0084237bcb8d36697554d25cc7d9a1ae1\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=6a419cfe9ccad5c9139b6109747cf48c75b702022ef56c5859a46dd165056da9\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "Successfully built pytorch-lifestream antlr4-python3-runtime\n",
      "Installing collected packages: tokenizers, antlr4-python3-runtime, pyDeprecate, omegaconf, hydra-core, huggingface-hub, transformers, pytorch-lightning, pytorch-lifestream\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 2.0.0\n",
      "    Uninstalling pytorch-lightning-2.0.0:\n",
      "      Successfully uninstalled pytorch-lightning-2.0.0\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 huggingface-hub-0.13.3 hydra-core-1.3.2 omegaconf-2.3.0 pyDeprecate-0.3.2 pytorch-lifestream-0.5.2 pytorch-lightning-1.6.5 tokenizers-0.13.2 transformers-4.27.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install pytorch-lifestream\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4or0wsz3eJJh"
   },
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import ParquetDataset, ParquetFiles\n",
    "\n",
    "iterable_train = ParquetDataset(ParquetFiles('train.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m80hD6-3eQON"
   },
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\n",
    "\n",
    "map_processed_train = MemoryMapDataset(\n",
    "    data=iterable_train,\n",
    "    i_filters=[\n",
    "        SeqLenFilter(min_seq_len=25),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRifFZ-TtLQq"
   },
   "source": [
    "# Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6mN_yKkoFGa"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, SplitRandom, SampleRandom\n",
    "from ptls.frames import PtlsDataModule\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "import logging\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "for encoder in ['gru', 'lstm']:\n",
    "  trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={},\n",
    "    embeddings={\n",
    "        'event_time': {'in': 800, 'out': 16},\n",
    "        'cat_id': {'in': 410, 'out': 16},\n",
    "      },\n",
    "  )\n",
    "\n",
    "  seq_encoder = RnnSeqEncoder(\n",
    "      trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "      hidden_size=256,\n",
    "      type=encoder,\n",
    "  )\n",
    "\n",
    "  model = CoLESModule(\n",
    "      seq_encoder=seq_encoder,\n",
    "      optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "      lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    "  )\n",
    "  train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        map_processed_train,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=200,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=2,\n",
    "    train_batch_size=256,\n",
    "  )\n",
    "  trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=False,\n",
    "  )\n",
    "\n",
    "\n",
    "  print(f'logger.version = {trainer.logger.version}')\n",
    "  trainer.fit(model, train_dl)\n",
    "  print(trainer.logged_metrics)\n",
    "  iterable_test = ParquetDataset(ParquetFiles('test.parquet'))\n",
    "\n",
    "  train_dl = inference_data_loader(list(iter(iterable_train)), num_workers=0, batch_size=256)\n",
    "\n",
    "  train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "  train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "\n",
    "  test_dl = inference_data_loader(list(iter(iterable_test)), num_workers=0, batch_size=256)\n",
    "  test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
    "  df_target = pd.read_csv('target_dataset_matched.csv')\n",
    "  df_target.rename(columns={'rtk':'user_id'},inplace=True)\n",
    "  df_target = df_target.set_index('user_id')\n",
    "  df_target.rename(columns={\"higher_education\": \"target\"}, inplace=True)\n",
    "\n",
    "  train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
    "  train_df['user_id'] = [x['user_id'] for x in iter(iterable_train)]\n",
    "  train_df = train_df.merge(df_target, how='left', on='user_id')\n",
    "\n",
    "  test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
    "  test_df['user_id'] = [x['user_id'] for x in iter(iterable_test)]\n",
    "  test_df = test_df.merge(df_target, how='left', on='user_id')\n",
    "  train_df.dropna(inplace=True)\n",
    "  test_df.dropna(inplace=True)\n",
    "  embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
    "  x_train, y_train = train_df[embed_columns], train_df['target']\n",
    "  x_test, y_test = test_df[embed_columns], test_df['target']\n",
    "  CatBoostModel = CatBoostClassifier(\n",
    "  iterations= 500,\n",
    "  learning_rate = 0.05,\n",
    "  use_best_model = True,\n",
    "  eval_metric ='AUC', \n",
    "  loss_function='Logloss',\n",
    "  random_seed = 42,\n",
    "  logging_level = 'Silent',\n",
    "  depth = 5)\n",
    "  CatBoostModel.fit(\n",
    "    x_train, y_train,\n",
    "    eval_set=(x_test, y_test),\n",
    "    plot=True\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "  )\n",
    "  y_pred = CatBoostModel.predict(x_test)\n",
    "  y_proba = CatBoostModel.predict_proba(x_test)\n",
    "  print(f'''{encoder} accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIB5G3lKgsBW",
    "outputId": "2390f338-26c8-4d76-9dbb-a48f2595b54a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7145049884881044 \n",
      "      f1: 0.8334825425246195, \n",
      "      precision: 1.0\n",
      "     roc auc : 0.5978396451959391\n"
     ]
    }
   ],
   "source": [
    "#gru\n",
    "print(f'''accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPF2_JJ9hDnR",
    "outputId": "78767c5e-63b6-4b4f-b208-e4a806b0053f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7145049884881044 \n",
      "      f1: 0.8334825425246195, \n",
      "      precision: 1.0\n",
      "     roc auc : 0.5765825854959981\n"
     ]
    }
   ],
   "source": [
    "#lstm\n",
    "print(f'''accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O1A1wl6taNZ"
   },
   "source": [
    "# Samplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTBY4qTHp6QD"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, SplitRandom, SampleRandom\n",
    "from ptls.frames import PtlsDataModule\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "import logging\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "for sampling in [SampleSlices, SplitRandom, SampleRandom]:\n",
    "  trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={},\n",
    "    embeddings={\n",
    "        'event_time': {'in': 800, 'out': 16},\n",
    "        'cat_id': {'in': 410, 'out': 16},\n",
    "      },\n",
    "  )\n",
    "\n",
    "  seq_encoder = RnnSeqEncoder(\n",
    "      trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "      hidden_size=256,\n",
    "      type='gru',\n",
    "  )\n",
    "\n",
    "  model = CoLESModule(\n",
    "      seq_encoder=seq_encoder,\n",
    "      optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "      lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    "  )\n",
    "  train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        map_processed_train,\n",
    "        splitter=sampling(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=200,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=2,\n",
    "    train_batch_size=256,\n",
    "  )\n",
    "  trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=False,\n",
    "  )\n",
    "\n",
    "\n",
    "  print(f'logger.version = {trainer.logger.version}')\n",
    "  trainer.fit(model, train_dl)\n",
    "  print(trainer.logged_metrics)\n",
    "  iterable_test = ParquetDataset(ParquetFiles('test.parquet'))\n",
    "\n",
    "  train_dl = inference_data_loader(list(iter(iterable_train)), num_workers=0, batch_size=256)\n",
    "\n",
    "  train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "  train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "\n",
    "  test_dl = inference_data_loader(list(iter(iterable_test)), num_workers=0, batch_size=256)\n",
    "  test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
    "  df_target = pd.read_csv('target_dataset_matched.csv')\n",
    "  df_target.rename(columns={'rtk':'user_id'},inplace=True)\n",
    "  df_target = df_target.set_index('user_id')\n",
    "  df_target.rename(columns={\"higher_education\": \"target\"}, inplace=True)\n",
    "\n",
    "  train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
    "  train_df['user_id'] = [x['user_id'] for x in iter(iterable_train)]\n",
    "  train_df = train_df.merge(df_target, how='left', on='user_id')\n",
    "\n",
    "  test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
    "  test_df['user_id'] = [x['user_id'] for x in iter(iterable_test)]\n",
    "  test_df = test_df.merge(df_target, how='left', on='user_id')\n",
    "  train_df.dropna(inplace=True)\n",
    "  test_df.dropna(inplace=True)\n",
    "  embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
    "  x_train, y_train = train_df[embed_columns], train_df['target']\n",
    "  x_test, y_test = test_df[embed_columns], test_df['target']\n",
    "  CatBoostModel = CatBoostClassifier(\n",
    "  iterations= 500,\n",
    "  learning_rate = 0.05,\n",
    "  use_best_model = True,\n",
    "  eval_metric ='AUC', \n",
    "  loss_function='Logloss',\n",
    "  random_seed = 42,\n",
    "  logging_level = 'Silent',\n",
    "  depth = 5)\n",
    "  CatBoostModel.fit(\n",
    "    x_train, y_train,\n",
    "    eval_set=(x_test, y_test),\n",
    "    plot=True\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "  )\n",
    "  y_pred = CatBoostModel.predict(x_test)\n",
    "  y_proba = CatBoostModel.predict_proba(x_test)\n",
    "  print(f'''{sampling.__class__.__name__} accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_ZKR_HG9Gna",
    "outputId": "49758875-d579-43ea-fd67-0333d06ab0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7145049884881044 \n",
      "      f1: 0.8331838565022421, \n",
      "      precision: 0.9978517722878625\n",
      "     roc auc : 0.6003199242345496\n"
     ]
    }
   ],
   "source": [
    "#SplitRandom\n",
    "print(f'''accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43vflmap9h9k",
    "outputId": "e7a5e722-cb2d-4ea2-8deb-40a5248ac2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7145049884881044 \n",
      "      f1: 0.8334825425246195, \n",
      "      precision: 1.0\n",
      "     roc auc : 0.5902140142984189\n"
     ]
    }
   ],
   "source": [
    "#SampleRandom\n",
    "print(f'''accuracy: {CatBoostModel.score(x_test, y_test)} \n",
    "      f1: {f1_score(y_pred, y_test)}, \n",
    "      precision: {precision_score(y_pred, y_test)}\n",
    "     roc auc : {roc_auc_score(y_test, y_proba[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ydfhU1qyv87c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FGQQ42Pw9HOU"
   },
   "outputs": [],
   "source": [
    "transactions = {'SampleSlices':0.7605643290172892, 'SplitRandom':0.7493132999027019, 'SampleRandom':0.7678373624728688}\n",
    "clickstream = {'SampleSlices':0.5978396451959391, 'SplitRandom':0.6003199242345496, 'SampleRandom':0.5902140142984189}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "k0HPip8gjAG_",
    "outputId": "7000ec33-6439-4c50-a297-c625639c5ccc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7af536dba42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclickstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'clickstream'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'transactions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "tr = pd.DataFrame(clickstream, index = ['clickstream'])\n",
    "tr1 = pd.DataFrame(transactions, index = ['transactions'])\n",
    "roc_auc = pd.concat([tr1, tr]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mpXMraqv4g6"
   },
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifxd5LNSjEhK"
   },
   "outputs": [],
   "source": [
    "clickstream = {'gru':0.5978396451959391, 'lstm': 0.5765825854959981}\n",
    "transactions = {'gru': 0.7605643290172892, 'lstm' : 0.7527879649726817}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H12ox_1gjdeZ"
   },
   "outputs": [],
   "source": [
    "tr = pd.DataFrame(clickstream, index = ['clickstream'])\n",
    "tr1 = pd.DataFrame(transactions, index = ['transactions'])\n",
    "roc_auc = pd.concat([tr1, tr]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8E8NPJOsji1l"
   },
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "5_S5MLmOkW7k",
    "outputId": "184a2072-943f-4d35-9463-e44fddd9ba40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3c530e47-6588-4e1e-96b7-0804968a2c0a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>clickstream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SampleSlices</th>\n",
       "      <td>0.760564</td>\n",
       "      <td>0.597840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SplitRandom</th>\n",
       "      <td>0.749313</td>\n",
       "      <td>0.600320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SampleRandom</th>\n",
       "      <td>0.767837</td>\n",
       "      <td>0.590214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c530e47-6588-4e1e-96b7-0804968a2c0a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3c530e47-6588-4e1e-96b7-0804968a2c0a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3c530e47-6588-4e1e-96b7-0804968a2c0a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              transactions  clickstream\n",
       "SampleSlices      0.760564     0.597840\n",
       "SplitRandom       0.749313     0.600320\n",
       "SampleRandom      0.767837     0.590214"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izEajziAnlJN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
